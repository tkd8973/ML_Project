import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
import xgboost as xgb
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from data import get_city_list, get_gu_list, get_town_list, get_village_list
from service import get_filtered_data, handle_preprocessing
import datetime

def main():
    with st.sidebar: sidebar()
    contents()

def sidebar() :
    title =  'ì§€ì—­ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'
    st.title(title)
    label_city_list = 'ì‹œ/ë„ ì„ íƒ'
    label_gu_list = 'ì‹œ/êµ°/êµ¬ ì„ íƒ'
    label_town_list = 'ì/ë©´/ë™ ì„ íƒ'
    city_choice = st.selectbox(label_city_list, get_city_list(),
    key='city')
    gu_choice = st.selectbox(label_gu_list, get_gu_list(city_choice),
    key='gu')
    town_choice = st.selectbox(label_town_list, get_town_list(city_choice, gu_choice),
    key='town')
    vl = get_village_list(city_choice, gu_choice, town_choice)
    if len(vl)>0:
        village_choice = st.selectbox(label_town_list, vl, key='village')

    else:
        st.session_state['village'] = ''


def col_():
        col1,col2 = st.columns([1, 1])
        with col1 :
            st.slider('ì „ìš© ë©´ì ì„ ì„ íƒí•´ ì£¼ì„¸ìš”', 0.0, 300.0)
            # st.write("ì „ìš© ë©´ì  ", area, '(ã¡)ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤.')
            st.markdown(f"<div style='margin-top: 25px;'></div>", unsafe_allow_html=True)
            genre = st.radio(
                "ê±°ë˜ ìœ í˜•ì„ ì„ íƒí•´ ì£¼ì„¸ìš” (ì¤‘ê°œê±°ë˜, ì§ê±°ë˜)",
                ('ì¤‘ê°œê±°ë˜', 'ì§ê±°ë˜'))
            st.markdown(f"<div style='margin-top: 25px; margin-right: 20px;'></div>", unsafe_allow_html=True)
        with col2 :
            st.slider('ê±´ì¶• ë…„ë„ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”', min_value = 1940, max_value=2023,step=1)
            # st.write("ê±´ì¶• ë…„ë„ ", year_of_construction, 'ë…„ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤.')
            st.markdown(f"<div style='margin-top: 25px;'></div>", unsafe_allow_html=True)
            if st.button('í˜„ì¬ ê¸ˆë¦¬ ì ìš©'):
                today = datetime.date.today()
            else:
                today = datetime.date.today()
        if st.button('ì˜ˆì¸¡'):
            st.write("ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡ ê°’ ì…ë‹ˆë‹¤")
        else:
            st.write("")


def contents():
    # st.write(get_filtered_data())
    # st.write(handle_preprocessing())

    tab0, tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(['df',"Linear Regressor", 'KNN', "Decision Tree", 'Random Forest', "XGBoost", "LightGBM"])
    
    with tab0:
        background()
        col_()
    with tab1: 
        tab1.subheader("ğŸ“ˆLinear RegressionğŸ“ˆ")
        lr() 
    with tab2: 
        tab2.subheader("ğŸ¤KNNğŸ¤")
        knn()
    with tab3:
        tab3.subheader("ğŸŒ²Decision TreeğŸŒ²")
        dct()
    with tab4:
        tab4.subheader("ğŸŒ³Random ForestğŸŒ³") 
        rdf()
    with tab5:
        tab5.subheader("ğŸ’ªXGBoostğŸ’ª") 
        xgb()
    with tab6: 
        tab6.subheader("âš¡ï¸LightGBMâš¡ï¸")
        lgbm()
        

def background():
    st.dataframe(handle_preprocessing())

# lr ëª¨ë¸
def lr():
    datas = handle_preprocessing()
    train = datas.loc[datas.index < '2023-01-01']
    test = datas.loc[datas.index >= '2023-01-01']
    X_train = train.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_train = train['í‰ë‹¹ê°€']
    X_test = test.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_test = test['í‰ë‹¹ê°€']

    models = []
    for i in range(0,5):
        if i==0:
            continue
        model = LinearRegression(n_jobs=-1)
        model.fit(X_train,y_train)

        pred= model.predict(X_test)
        rmse = mean_squared_error(y_test,pred)**0.5
        
        models.append(rmse)
    st.write('ëª¨ë¸ì˜ RMSE ê°’',models)
    st.write('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’',pred)


# knn ëª¨ë¸
def knn():
    datas = handle_preprocessing()
    train = datas.loc[datas.index < '2023-01-01']
    test = datas.loc[datas.index >= '2023-01-01']
    X_train = train.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_train = train['í‰ë‹¹ê°€']
    X_test = test.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_test = test['í‰ë‹¹ê°€']

    models = []
    for i in range(0,5):
        if i==0:
            continue
        model = KNeighborsRegressor(n_neighbors=i,weights='distance')
        model.fit(X_train,y_train)

        pred=model.predict(X_test)
        rmse = mean_squared_error(y_test,pred)**0.5
        
        models.append(rmse)

    st.write(models)
    st.write('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’',pred)

# ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸
def rdf():
    datas = handle_preprocessing()
    train = datas.loc[datas.index < '2023-01-01']
    test = datas.loc[datas.index >= '2023-01-01']
    X_train = train.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_train = train['í‰ë‹¹ê°€']
    X_test = test.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_test = test['í‰ë‹¹ê°€']

    models = []
    for i in range(0,5):
        if i==0:
            continue
        model = RandomForestRegressor(n_estimators=150,max_depth=4)
        model.fit(X_train,y_train)

        pred=model.predict(X_test)
        rmse = mean_squared_error(y_test,pred)**0.5
        
        models.append(rmse)

    st.write(models)
    st.write('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’',pred)

# ê²°ì •íŠ¸ë¦¬ ëª¨ë¸
def dct():
    datas = handle_preprocessing()
    train = datas.loc[datas.index < '2023-01-01']
    test = datas.loc[datas.index >= '2023-01-01']
    X_train = train.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_train = train['í‰ë‹¹ê°€']
    X_test = test.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_test = test['í‰ë‹¹ê°€']

    models = []
    for i in range(0,5):
        if i==0:
            continue
        model = DecisionTreeRegressor(random_state=i)
        model.fit(X_train,y_train)

        pred=model.predict(X_test)
        rmse = mean_squared_error(y_test,pred)**0.5
        
        models.append(rmse)

    st.write(models)
    st.write('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’',pred)

# XGBoost ëª¨ë¸
def xgb():
    datas = handle_preprocessing()
    train = datas.loc[datas.index < '2023-01-01']
    test = datas.loc[datas.index >= '2023-01-01']
    X_train = train.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_train = train['í‰ë‹¹ê°€']
    X_test = test.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_test = test['í‰ë‹¹ê°€']

    models = []
    for i in range(0,5):
        if i==0:
            continue
        model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=100)
        model.fit(X_train,y_train)

        pred=model.predict(X_test)
        rmse = mean_squared_error(y_test,pred)**0.5
        models.append(rmse)

    st.write(models)
    st.write('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’',pred)

# LGBM ëª¨ë¸
def lgbm():
    datas = handle_preprocessing()
    train = datas.loc[datas.index < '2023-01-01']
    test = datas.loc[datas.index >= '2023-01-01']
    X_train = train.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_train = train['í‰ë‹¹ê°€']
    X_test = test.drop(['ì‹œêµ°êµ¬','ê±°ë˜ê¸ˆì•¡(ë§Œì›)','í‰ë‹¹ê°€'],axis=1)
    y_test = test['í‰ë‹¹ê°€']

    models = []
    for i in range(0,5):
        if i==0:
            continue
        model = LGBMRegressor(num_leaves=16, max_depth=4, learning_rate=0.1)
        model.fit(X_train,y_train)

        pred=model.predict(X_test)
        rmse = mean_squared_error(y_test,pred)**0.5
        models.append(rmse)

    st.write(models)
    st.write('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’',pred)

if __name__ == '__main__':
    main()